{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import alphashape\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "    # load file\n",
    "    # convert it into our dataset\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"pose_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = sys.argv[1]\n",
    "# DB = db_pck.load_db(env_var_db_path)\n",
    "# data_path = load_path(DB.fetch_path(data_key))\n",
    "dataset = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisheye correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCameraMatrix(data_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrectVideo(cap, camera_matrix, output_path=\"output/output\", show_output = False): #video\n",
    "    K = camera_matrix.K\n",
    "    D = camera_matrix.D\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K, D, (width, height), None)\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, (width, height), cv2.CV_16SC2)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Undistort the frame using the precomputed maps\n",
    "        undistorted_frame = cv2.remap(frame, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if show_output:\n",
    "        # Show the frame (optional)\n",
    "            cv2.imshow(\"Undistorted Video\", undistorted_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Write to output file\n",
    "        \n",
    "        out.write(undistorted_frame)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    c_video = cv2.VideoCapture(output_path)\n",
    "    return c_video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapose stopgap code\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"test4.mkv\")        #dataset.GetVideo()\n",
    "camera_matrix = LoadCameraMatrix(data_path + \"/camera_matrix\") # dataset.meta.camera_matrix\n",
    "c_video = CorrectVideo(video, camera_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPose(c_video, show_output=False):\n",
    "    result_list = []\n",
    "    while c_video.isOpened():\n",
    "        ret, frame = c_video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe Pose\n",
    "        results = pose.process(rgb_frame)\n",
    "\n",
    "        # Draw pose landmarks on the frame\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "            )\n",
    "        \n",
    "        result_list.append(results) #check if deep copy needed\n",
    "\n",
    "        # Display the frame\n",
    "        if show_output:\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            # Exit loop on pressing 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    c_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe stopgap code\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Draw pose landmarks on the frame\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "        )\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('MediaPipe Pose', frame)\n",
    "\n",
    "    # Exit loop on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_info = GetPose(video) #GetPose(c_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit vector extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractPoints(pose_info):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PointsToUnitVectors(points, camera_frame):\n",
    "    ones = np.ones((points.shape[0], 1))\n",
    "    direction_vectors = np.hstack((points.reshape(-1, 2), ones))\n",
    "    direction_vectors /= np.linalg.norm(direction_vectors, axis=1, keepdims=True)\n",
    "    return direction_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCameraFrame(data_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points2D = ExtractPoints(pose_info)\n",
    "camera_frame = LoadCameraFrame(data_path + \"/camera_matrix\") #dataset.meta.camera_frame\n",
    "unit_vectors = PointsToUnitVectors(points2D, dataset.meta.camera_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquares(unit_vectors, point_distance_pairs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConstPairs(data_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_pairs = GetConstPairs(data_path + \"/rider_keypointpairs\") #dataset.meta.rider_info.GetConstPairs()\n",
    "points3D = LeastSquares(unit_vectors, const_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points to Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit3DMesh(points, mesh):\n",
    "    # Instead of fitting the mesh, just extend an ourline\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRiderMesh(data_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = GetRiderMesh(data_path + \"/camera_matrix\")#dataset.meta.rider_info.GetMesh()\n",
    "polyline = Fit3DMesh(points3D, mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection to Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePlane(normal_vec, camera_pos):\n",
    "    return (normal_vec, camera_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectToPlane(polyline, plane):\n",
    "    polyline[:, 2] = 0  # Set Z-coordinates to 0\n",
    "    return polyline\n",
    "    #normal = plane[0] / np.linalg.norm(plane[0])  # Normalize normal vector\n",
    "\n",
    "    # Compute distances from points to the plane\n",
    "    #d = np.dot(polyline - plane[1], normal) / np.dot(normal, normal)\n",
    "\n",
    "    # Compute projected points\n",
    "    #projected_points = polyline - d[:, np.newaxis] * normal\n",
    "\n",
    "    #return projected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = CreatePlane(dataset.wind_direction)\n",
    "polyshape = ProjectToPlane(polyline, plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate CdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetArea(polyshape, alpha = 0.3):\n",
    "    alpha_shape = alphashape.alphashape(polyshape, alpha)\n",
    "    if isinstance(alpha_shape, Polygon):  # Ensure it's a polygon, not a multipolygon\n",
    "        area = alpha_shape.area\n",
    "        print(f\"Alpha Shape Area: {area:.2f} square units\")\n",
    "    else:\n",
    "        print(\"Alpha shape resulted in multiple disconnected components\")\n",
    "        return 0 # later iterate through components\n",
    "    return alpha_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateCdA(area, coifs=[0.3]):\n",
    "    return area*coifs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateDrag(velocity, cda, air_density=1):\n",
    "    return 0.5 * air_density * cda * velocity**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateRelative(power, drag, in_per):\n",
    "    return 100*drag/power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = GetArea(polyshape)\n",
    "CdA = CalculateCdA(area)\n",
    "drag = CalculateDrag(dataset.velocity, CdA)\n",
    "rel_power = CalculateRelative(dataset.power, drag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_video(c_video)\n",
    "#overlay(pose_info)\n",
    "#overlay(polyshape)\n",
    "\n",
    "#draw3D(points3D)\n",
    "#draw3D(polyline)\n",
    "#draw2D(polyshape)\n",
    "\n",
    "#drawLabel(area, CdA, drag, rel_power, dataset.velocity, dataset.power)\n",
    "#drawGraphs(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
